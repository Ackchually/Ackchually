{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LLguOepLN7zu",
        "ipuOQX2zna5k",
        "VlQ9ddWGxpFR",
        "Z_-oQKDEM_J_",
        "A1qOsZW2jN_O"
      ],
      "authorship_tag": "ABX9TyM6ze/kGvjsBEGyJojz+Hjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ackchually/Ackchually/blob/main/Filter_and_Sorting_data_within_6_months.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Upload Your CSV that u want to input data to main file\n",
        "* Press run all at runtime tab under title\n",
        "* Download the processed main file (✅ Bottom of page)\n",
        "* In case of errors, Check the tab below and run again (make sure the file name is specified correctly)\n",
        "* Extracted CSV should only have AssignedName and Data\n",
        "* Modified Main File cannot be processed"
      ],
      "metadata": {
        "id": "w37FsToXR9u1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install latest library to the virtual machine"
      ],
      "metadata": {
        "id": "LLguOepLN7zu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YazZWtPLFW2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5293d837-9ae3-4b7a-8848-e90e11395090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install -U pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -v \"openpyxl==3.1.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3A0JkgFEVOr",
        "outputId": "b8a024fd-c922-43eb-86c2-0616364752f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.0.1 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openpyxl==3.1.0\n",
            "  Downloading openpyxl-3.1.0-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl==3.1.0) (1.1.0)\n",
            "Installing collected packages: openpyxl\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.0.10\n",
            "    Uninstalling openpyxl-3.0.10:\n",
            "      Removing file or directory /usr/local/lib/python3.9/dist-packages/openpyxl-3.0.10.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.9/dist-packages/openpyxl/\n",
            "      Successfully uninstalled openpyxl-3.0.10\n",
            "Successfully installed openpyxl-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "B74Gm41A60mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Edit Main File Name Here"
      ],
      "metadata": {
        "id": "ipuOQX2zna5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file\n",
        "file_name = 'MainFile.xlsx'\n",
        "book = openpyxl.load_workbook(file_name)"
      ],
      "metadata": {
        "id": "sw0hOO4TFdHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loop through all the sheets and create a csv for each sheet\n",
        "for sheet_name, df in pd.read_excel(r\"MainFile.xlsx\", index_col=-1, sheet_name=None).items():\n",
        "      df.to_csv(f'{sheet_name}.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "9qnc3CDavX7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Edit CSV Here"
      ],
      "metadata": {
        "id": "VlQ9ddWGxpFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a dataset from a CSV file\n",
        "df = pd.read_csv('Events_20230426_1682499388988.csv')\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "PAivQmF1Fh2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4529554b-6f95-40c9-feb9-fc9af3a4a056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove Duplicates and Filtering Data"
      ],
      "metadata": {
        "id": "Z_-oQKDEM_J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   # Filter the DataFrame based on multiple criteria\n",
        "Antfiltered_df = df.loc[(df['AssignedName'] == 'Ant_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Antdeduplicated_df = Antfiltered_df.drop_duplicates()\n",
        "\n",
        "Antipdf = Antdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "x0c63OdAGYAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Beefiltered_df = df.loc[(df['AssignedName'] == 'Bee_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Beededuplicated_df = Beefiltered_df.drop_duplicates()\n",
        "\n",
        "Beeipdf = Beededuplicated_df['Data']\n"
      ],
      "metadata": {
        "id": "4Z2hWR7HGuFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Birdfiltered_df = df.loc[(df['AssignedName'] == 'Bird_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Birddeduplicated_df = Birdfiltered_df.drop_duplicates()\n",
        "\n",
        "Birdipdf = Birddeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "PV4xtU0GHART"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Catfiltered_df = df.loc[(df['AssignedName'] == 'Cat_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Catdeduplicated_df = Catfiltered_df.drop_duplicates()\n",
        "\n",
        "Catipdf = Catdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "jI_eIJCwFl-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Cowfiltered_df = df.loc[(df['AssignedName'] == 'Cow_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Cowdeduplicated_df = Cowfiltered_df.drop_duplicates()\n",
        "\n",
        "Cowipdf = Cowdeduplicated_df['Data']\n",
        "\n",
        "print(Cowipdf)\n"
      ],
      "metadata": {
        "id": "l2RK3xfSHNDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Dogfiltered_df = df.loc[(df['AssignedName'] == 'Dog_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Dogdeduplicated_df = Dogfiltered_df.drop_duplicates()\n",
        "\n",
        "Dogipdf = Dogdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "rrmXH1_IFk86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Fishfiltered_df = df.loc[(df['AssignedName'] == 'Fish_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Fishdeduplicated_df = Fishfiltered_df.drop_duplicates()\n",
        "\n",
        "Fishipdf = Fishdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "lDsdOTQbHr2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Frogfiltered_df = df.loc[(df['AssignedName'] == 'Frog_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Frogdeduplicated_df = Frogfiltered_df.drop_duplicates()\n",
        "\n",
        "Frogipdf = Frogdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "ej0gTSDaILj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Ratfiltered_df = df.loc[(df['AssignedName'] == 'Rat_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Ratdeduplicated_df = Ratfiltered_df.drop_duplicates()\n",
        "\n",
        "Ratipdf = Ratdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "MviuO_zgFolj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Filter the DataFrame based on multiple criteria\n",
        "Horsefiltered_df = df.loc[(df['AssignedName'] == 'Horse_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Horsededuplicated_df = Horsefiltered_df.drop_duplicates()\n",
        "\n",
        "Horseipdf = Horsededuplicated_df['Data']\n"
      ],
      "metadata": {
        "id": "x8AL0USfIZmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Filter the DataFrame based on multiple criteria\n",
        "Lionfiltered_df = df.loc[(df['AssignedName'] == 'Lion_Collector')]\n",
        "\n",
        "    # Drop duplicate rows from the filtered DataFrame\n",
        "Liondeduplicated_df = Lionfiltered_df.drop_duplicates()\n",
        "\n",
        "Lionipdf = Liondeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "021mLLfGIlnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "      # Filter the DataFrame based on multiple criteria\n",
        "Monkfiltered_df = df.loc[(df['AssignedName'] == 'Monk_Collector')]\n",
        "\n",
        "      # Drop duplicate rows from the filtered DataFrame\n",
        "Monkdeduplicated_df = Monkfiltered_df.drop_duplicates()\n",
        "\n",
        "Monkipdf = Monkdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "aKag6adeI5iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "      # Filter the DataFrame based on multiple criteria\n",
        "Pigfiltered_df = df.loc[(df['AssignedName'] == 'Pig_Collector')]\n",
        "\n",
        "      # Drop duplicate rows from the filtered DataFrame\n",
        "Pigdeduplicated_df = Pigfiltered_df.drop_duplicates()\n",
        "\n",
        "Pigipdf = Pigdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "yRyl6zWCJQOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "      # Filter the DataFrame based on multiple criteria\n",
        "Rabbitfiltered_df = df.loc[(df['AssignedName'] == 'Rabbit_Collector')]\n",
        "\n",
        "Rabbitdeduplicated_df = Rabbitfiltered_df.drop_duplicates()\n",
        "\n",
        "Rabbitipdf = Rabbitdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "A_BLbFDd1sha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "      # Filter the DataFrame based on multiple criteria\n",
        "Sheepfiltered_df = df.loc[(df['AssignedName'] == 'Sheep_Collector')]\n",
        "\n",
        "      # Drop duplicate rows from the filtered DataFrame\n",
        "Sheepdeduplicated_df = Sheepfiltered_df.drop_duplicates()\n",
        "\n",
        "Sheepipdf = Sheepdeduplicated_df['Data']"
      ],
      "metadata": {
        "id": "4Ml3H5GO10sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "      # Filter the DataFrame based on multiple criteria\n",
        "Snakefiltered_df = df.loc[(df['AssignedName'] == 'Snake_Collector')]\n",
        "\n",
        "Snakededuplicated_df = Snakefiltered_df.drop_duplicates()\n",
        "\n",
        "Snakeipdf = Snakededuplicated_df['Data']"
      ],
      "metadata": {
        "id": "GHSRRXvX1_Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove Duplicates within 6 months"
      ],
      "metadata": {
        "id": "A1qOsZW2jN_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "# Get the current date\n",
        "now = datetime.now()\n",
        "\n",
        "# Subtract 6 months from the current date\n",
        "six_months_ago = now - relativedelta(months=6)\n",
        "\n",
        "# Print the date that is 6 months ago\n",
        "print(six_months_ago)\n"
      ],
      "metadata": {
        "id": "ghUBETa6kV3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391398ed-f560-4265-845d-51f3cbf9cee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-26 09:02:44.639552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = pd.read_csv('Ant.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "a[\"Date\"] = pd.to_datetime(a[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "b = a.loc[a[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "    # b not in c\n",
        "FinalAntipdf = Antipdf.loc[~Antipdf.isin(b)]\n",
        "print(FinalAntipdf)"
      ],
      "metadata": {
        "id": "o_wImVNfjOtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "c = pd.read_csv('Bee.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "c[\"Date\"] = pd.to_datetime(c[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "d = c.loc[c[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalBeeipdf = Beeipdf.loc[~Beeipdf.isin(d)]\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "FniKAv6Lm_0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "e = pd.read_csv('Bird.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "e[\"Date\"] = pd.to_datetime(e[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "f = e.loc[e[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalBirdipdf = Birdipdf.loc[~Birdipdf.isin(f)]"
      ],
      "metadata": {
        "id": "qKlXBxunn384"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "g = pd.read_csv('Cat.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "g[\"Date\"] = pd.to_datetime(g[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "h = g.loc[g[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalCatipdf = Catipdf.loc[~Catipdf.isin(h)]"
      ],
      "metadata": {
        "id": "Wi7oFtIKoE8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = pd.read_csv('Cow.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "i[\"Date\"] = pd.to_datetime(i[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "j = i.loc[i[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalCowipdf = Cowipdf.loc[~Cowipdf.isin(j)]"
      ],
      "metadata": {
        "id": "4cFNu6BYovoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = pd.read_csv('Dog.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "k[\"Date\"] = pd.to_datetime(k[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "l = k.loc[k[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalDogipdf = Dogipdf.loc[~Dogipdf.isin(l)]"
      ],
      "metadata": {
        "id": "qKe8nwSso_EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = pd.read_csv('Fish.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "m[\"Date\"] = pd.to_datetime(m[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "n = m.loc[m[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalFishipdf = Fishipdf.loc[~Fishipdf.isin(n)]"
      ],
      "metadata": {
        "id": "uIXKw0wopNXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "o = pd.read_csv('Frog.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "o[\"Date\"] = pd.to_datetime(o[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "p = o.loc[o[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalFrogipdf = Frogipdf.loc[~Frogipdf.isin(p)]"
      ],
      "metadata": {
        "id": "A4B3OkYxp1Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = pd.read_csv('Rat.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "q[\"Date\"] = pd.to_datetime(q[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "r = q.loc[q[\"Date\"] > six_months_ago , \" Data\"]\n",
        "\n",
        "FinalRatipdf = Ratipdf.loc[~Ratipdf.isin(r)]\n",
        "print(FinalRatipdf)"
      ],
      "metadata": {
        "id": "K7bN3PuBqLZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.read_csv('Horse.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "s[\"Date\"] = pd.to_datetime(s[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "t = s.loc[s[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalHorseipdf = Horseipdf.loc[~Horseipdf.isin(t)]"
      ],
      "metadata": {
        "id": "lxh-xsL0qcSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = pd.read_csv('Lion.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "u[\"Date\"] = pd.to_datetime(u[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "v = u.loc[u[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalLionipdf = Lionipdf.loc[~Lionipdf.isin(v)]"
      ],
      "metadata": {
        "id": "6eqF8-IpqrJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = pd.read_csv('Monk.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "w[\"Date\"] = pd.to_datetime(w[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "x = w.loc[w[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalMonkipdf = Monkipdf.loc[~Monkipdf.isin(x)]"
      ],
      "metadata": {
        "id": "01DZ54ImsKM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.read_csv('Pig.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "y[\"Date\"] = pd.to_datetime(y[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "z = y.loc[y[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalPigipdf = Pigipdf.loc[~Pigipdf.isin(z)]"
      ],
      "metadata": {
        "id": "dnl1qeqPsaI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab = pd.read_csv('Rabbit.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "ab[\"Date\"] = pd.to_datetime(ab[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "cde = ab.loc[ab[\"Date\"] > six_months_ago , \" Data\"]\n",
        "\n",
        "FinalRabbitipdf = Rabbitipdf.loc[~Rabbitipdf.isin(cde)]"
      ],
      "metadata": {
        "id": "v0sYFKD8sWl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ef = pd.read_csv('Sheep.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "ef[\"Date\"] = pd.to_datetime(ef[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "gh = ef.loc[ef[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalSheepipdf = Sheepipdf.loc[~Sheepipdf.isin(gh)]"
      ],
      "metadata": {
        "id": "f9T4_TEetnSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ij = pd.read_csv('Snake.csv')\n",
        "    # Convert the date column to a datetime object\n",
        "ij[\"Date\"] = pd.to_datetime(ij[\"Date\"],errors='coerce')\n",
        "\n",
        "    # Filter the rows where the date is greater than 6 months\n",
        "kl = ij.loc[ij[\"Date\"] > six_months_ago , \"Data\"]\n",
        "\n",
        "FinalSnakeipdf = Snakeipdf.loc[~Snakeipdf.isin(kl)]"
      ],
      "metadata": {
        "id": "dpF1gqZmt2Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Edit Main File Name Here"
      ],
      "metadata": {
        "id": "Tv2topmvP12G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(\"MainFile.xlsx\", engine=\"openpyxl\", mode='a', if_sheet_exists='overlay') as writer:\n",
        "        FinalAntipdf.to_excel(writer, sheet_name='Ant', startrow=writer.sheets['Ant'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalBeeipdf.to_excel(writer, sheet_name='Bee', startrow=writer.sheets['Bee'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalBirdipdf.to_excel(writer, sheet_name='Bird', startrow=writer.sheets['Bird'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalCatipdf.to_excel(writer, sheet_name='Cat', startrow=writer.sheets['Cat'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalCowipdf.to_excel(writer, sheet_name='Cow', startrow=writer.sheets['Cow'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalDogipdf.to_excel(writer, sheet_name='Dog', startrow=writer.sheets['Dog'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalFishipdf.to_excel(writer, sheet_name='Fish', startrow=writer.sheets['Fish'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalFrogipdf.to_excel(writer, sheet_name='Frog', startrow=writer.sheets['Frog'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalRatipdf.to_excel(writer, sheet_name='Rat', startrow=writer.sheets['Rat'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalHorseipdf.to_excel(writer, sheet_name='Horse', startrow=writer.sheets['Horse'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalLionipdf.to_excel(writer, sheet_name='Lion', startrow=writer.sheets['Lion'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalMonkipdf.to_excel(writer, sheet_name='Monk', startrow=writer.sheets['Monk'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalPigipdf.to_excel(writer, sheet_name='Pig', startrow=writer.sheets['Pig'].max_row, startcol=1, index=False, header=False)\n",
        "        FinalRabbitipdf.to_excel(writer, sheet_name='Rabbit', startrow=writer.sheets['Rabbit'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalSheepipdf.to_excel(writer, sheet_name='Sheep', startrow=writer.sheets['Sheep'].max_row, startcol=2, index=False, header=False)\n",
        "        FinalSnakeipdf.to_excel(writer, sheet_name='Snake', startrow=writer.sheets['Snake'].max_row, startcol=2, index=False, header=False)\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "id": "QOYSe12mQcXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}